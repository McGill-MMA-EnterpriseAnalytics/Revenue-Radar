{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/Abdul/Desktop/MMA/Enterprise Data Science/Revenue-Radar/Data/train_dejsonified.csv', parse_dates=['date'])\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cutoff date for the split\n",
    "test_start_date = pd.Timestamp('2017-05-01')\n",
    "train_df = df[df['date'] < test_start_date]\n",
    "test_df = df[df['date'] >= test_start_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sources = pd.concat([train_df['source'], test_df['source']]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(data, pca=None, fit=False):\n",
    "    if fit:\n",
    "        pca = PCA(n_components=3)\n",
    "        pca.fit(data)\n",
    "    if not pca:\n",
    "        raise ValueError(\"PCA model is not provided for transformation.\")\n",
    "    transformed_data = pca.transform(data)\n",
    "    return transformed_data, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, all_sources, pca_model=None, fit_pca=False):\n",
    "    # Handle one-hot encoding for 'source'\n",
    "    source_df = pd.DataFrame(df[['source', 'fullVisitorId']])\n",
    "    one_hot_encoded_df = pd.get_dummies(source_df['source'], prefix='', prefix_sep='', dtype=int)\n",
    "\n",
    "    # Ensure all possible columns are included, filling missing with 0\n",
    "    one_hot_encoded_df = one_hot_encoded_df.reindex(columns=all_sources, fill_value=0)\n",
    "    one_hot_encoded_df['fullVisitorId'] = source_df['fullVisitorId']\n",
    "    source_df = one_hot_encoded_df.groupby('fullVisitorId').sum().reset_index()\n",
    "\n",
    "    \n",
    "    # Remove 'fullVisitorId' temporarily for PCA processing\n",
    "    pca_data = source_df.drop('fullVisitorId', axis=1).to_numpy()\n",
    "\n",
    "    \n",
    "    # Fit and transform PCA on the training data, or just transform on the test data\n",
    "    transformed_data, pca_model = apply_pca(pca_data, pca_model, fit=fit_pca)\n",
    "    \n",
    "    # Convert PCA output to DataFrame and create meaningful column names\n",
    "    pca_column_names = ['Source_PC1', 'Source_PC2', 'Source_PC3']\n",
    "    pca_df = pd.DataFrame(transformed_data, columns=pca_column_names)\n",
    "    pca_df['fullVisitorId'] = source_df['fullVisitorId'].values  # Ensure correct alignment\n",
    "    \n",
    "    # Fill missing values for 'pageviews' and 'bounces'\n",
    "    df['pageviews'].fillna(0, inplace=True)\n",
    "    df['bounces'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Replace missing 'transactionRevenue' with 0 and convert to int\n",
    "    df['transactionRevenue'].fillna(0, inplace=True)\n",
    "    df['transactionRevenue'] = df['transactionRevenue'].astype(int)\n",
    "    \n",
    "    # Create a binary 'Conversion' flag\n",
    "    df['Conversion'] = df['transactionRevenue'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    df['at_least_one_conversion'] = df.groupby('fullVisitorId')['Conversion'].transform('sum').apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    # Sort data by 'fullVisitorId' and 'date'\n",
    "    df.sort_values(by=['fullVisitorId', 'date'], inplace=True)\n",
    "    \n",
    "    # Identify and drop constant columns except 'bounces'\n",
    "    constant_columns = [col for col in df.columns if df[col].nunique() == 1 and col not in['Bounces','isTrueDirect']]    \n",
    "    df.drop(constant_columns, axis=1, inplace=True)\n",
    "    \n",
    "    # Drop other unnecessary columns\n",
    "    df.drop(['networkDomain', 'visitStartTime', 'visitNumber'], axis=1, inplace=True)\n",
    "    \n",
    "    # Merge data frames for channel visit analysis\n",
    "    first_visit_channel = df.groupby('fullVisitorId')['channelGrouping'].first().reset_index(name='FirstChannelVisit')\n",
    "    last_visit_channel = df.groupby('fullVisitorId')['channelGrouping'].last().reset_index(name='LastChannelVisit')\n",
    "    channels_first_last = pd.merge(first_visit_channel, last_visit_channel, on='fullVisitorId', how='inner')\n",
    "    \n",
    "    df_unique = df.drop_duplicates(subset='fullVisitorId', keep='first')\n",
    "    channels_first_last = pd.merge(channels_first_last, df_unique[['fullVisitorId', 'at_least_one_conversion', 'country', 'continent', 'subContinent']].drop_duplicates(), on='fullVisitorId', how='inner')\n",
    "    \n",
    "    \n",
    "    # Calculating the total number of visits by each user\n",
    "    total_visits_by_user=dict(df['fullVisitorId'].value_counts().reset_index(name='TotalVisits').values)\n",
    "\n",
    "    \n",
    "    # Calculating visits by channel for each user\n",
    "    channel_visits_by_user=dict(df.groupby('fullVisitorId')['channelGrouping'].value_counts())\n",
    "    list_of_dicts = []\n",
    "    for (visitor_id, channel), visits in channel_visits_by_user.items():\n",
    "        list_of_dicts.append({'fullVisitorId': visitor_id, channel: visits})\n",
    "\n",
    "    # Creating a DataFrame\n",
    "    df_channel_visits = pd.DataFrame(list_of_dicts)\n",
    "\n",
    "    # Combining all dictionaries representing the same fullVisitorId\n",
    "    df_channel_visits = df_channel_visits.groupby('fullVisitorId', as_index=False).sum()\n",
    "\n",
    "    \n",
    "    # Total pageviews by user\n",
    "    total_pageviews_by_user=dict(df.groupby('fullVisitorId')['pageviews'].sum().reset_index(name='TotalPageviews').values)\n",
    "\n",
    "    # Total bounces by user\n",
    "    total_bounces_by_user=dict(df.groupby('fullVisitorId')['bounces'].sum().reset_index(name='TotalBounces').values)\n",
    "\n",
    "\n",
    "    visits_by_device=dict(df.groupby('fullVisitorId')['deviceCategory'].value_counts())\n",
    "    # converting the dictionary to a list of dictionaries\n",
    "    list_of_dicts = []\n",
    "    for (visitor_id, device), visits in visits_by_device.items():\n",
    "        list_of_dicts.append({'fullVisitorId': visitor_id, device: visits})\n",
    "\n",
    "    # Creating a DataFrame\n",
    "    df_visits_by_device = pd.DataFrame(list_of_dicts)\n",
    "\n",
    "    # Combining all dictionaries representing the same fullVisitorId\n",
    "    df_visits_by_device = df_visits_by_device.groupby('fullVisitorId', as_index=False).sum()\n",
    "    \n",
    "    # Session pageviews\n",
    "    first_session_pageviews=dict(df.groupby('fullVisitorId')['pageviews'].first().reset_index(name='FirstSessionPageviews').values)\n",
    "    last_session_pageviews=dict(df.groupby('fullVisitorId')['pageviews'].last().reset_index(name='LastSessionPageviews').values)\n",
    "    \n",
    "    # Campaign data adjustment\n",
    "    df['campaign'] = df['campaign'].apply(lambda x: 0 if x == '(not set)' else 1)\n",
    "    \n",
    "    # Calculating campaign visits\n",
    "    campaign_visits_by_user=dict(df.groupby('fullVisitorId')['campaign'].sum().reset_index(name='CampaignVisits').values)\n",
    "\n",
    "    \n",
    "    # TrueDirect and AdContent data handling\n",
    "    df['isTrueDirect'] = df['isTrueDirect'].fillna(False)\n",
    "    true_Direct_by_user=dict(df.groupby('fullVisitorId')['isTrueDirect'].sum().reset_index(name='isTrueDirect').values)\n",
    "\n",
    "    adcontent_by_user=dict(df.groupby('fullVisitorId')['adContent'].apply(lambda x: x.notnull().sum()).reset_index(name='AdContentVisits').values)\n",
    "\n",
    "\n",
    "    # Convert dictionaries to DataFrames\n",
    "    df_total_bounces = pd.DataFrame(list(total_bounces_by_user.items()), columns=['fullVisitorId', 'TotalBounces'])\n",
    "    df_total_visits = pd.DataFrame(list(total_visits_by_user.items()), columns=['fullVisitorId', 'TotalVisits'])\n",
    "    df_total_pageviews = pd.DataFrame(list(total_pageviews_by_user.items()), columns=['fullVisitorId', 'TotalPageviews'])\n",
    "    df_first_session_pageviews = pd.DataFrame(list(first_session_pageviews.items()), columns=['fullVisitorId', 'FirstSessionPageviews'])\n",
    "    df_last_session_pageviews = pd.DataFrame(list(last_session_pageviews.items()), columns=['fullVisitorId', 'LastSessionPageviews'])\n",
    "    df_campaign_visits = pd.DataFrame(list(campaign_visits_by_user.items()), columns=['fullVisitorId', 'CampaignVisits'])\n",
    "    df_true_Direct = pd.DataFrame(list(true_Direct_by_user.items()), columns=['fullVisitorId', 'isTrueDirect'])\n",
    "    df_adcontent_visits = pd.DataFrame(list(adcontent_by_user.items()), columns=['fullVisitorId', 'AdContentVisits'])\n",
    "\n",
    "    # Merging all computed DataFrames\n",
    "    data_frames_to_merge = [\n",
    "        df_total_visits, df_total_bounces, df_channel_visits,\n",
    "        df_total_pageviews, df_visits_by_device, df_first_session_pageviews,\n",
    "        df_last_session_pageviews, df_campaign_visits, df_true_Direct,pca_df,\n",
    "        df_adcontent_visits\n",
    "    ]\n",
    "\n",
    "    final_df = channels_first_last\n",
    "    for data_frame in data_frames_to_merge:\n",
    "        final_df = pd.merge(final_df, data_frame, on='fullVisitorId', how='inner')\n",
    "    \n",
    "    # Convert any floating-point columns to integers if necessary\n",
    "    for col in final_df.select_dtypes(include=['float64']).columns:\n",
    "        final_df[col] = final_df[col].astype(int)\n",
    "\n",
    "    return final_df, pca_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply preprocessing to both train and test datasets\n",
    "processed_train, pca_model = preprocess_data(train_df, all_sources, fit_pca=True)\n",
    "processed_test, _ = preprocess_data(test_df, all_sources, pca_model=pca_model, fit_pca=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(567490, 29)\n",
      "(161282, 29)\n"
     ]
    }
   ],
   "source": [
    "print(processed_train.shape)\n",
    "print(processed_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test.to_csv('/Users/Abdul/Desktop/MMA/Enterprise Data Science/test_df.csv', index=False)\n",
    "processed_train.to_csv('/Users/Abdul/Desktop/MMA/Enterprise Data Science/train_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
