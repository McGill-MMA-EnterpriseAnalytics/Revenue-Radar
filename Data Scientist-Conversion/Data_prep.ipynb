{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/Abdul/Desktop/MMA/Enterprise Data Science/Revenue-Radar/Data/train_dejsonified.csv', parse_dates=['date'])\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cutoff date for the split\n",
    "test_start_date = pd.Timestamp('2017-04-01')\n",
    "train_df = df[df['date'] < test_start_date]\n",
    "test_df = df[df['date'] >= test_start_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_train and df_test are your initial train and test datasets\n",
    "all_sources = pd.concat([train_df['source'], test_df['source']]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, all_sources):\n",
    "    # Handle one-hot encoding for 'source'\n",
    "    source_df = pd.DataFrame(df[['source', 'fullVisitorId']])\n",
    "    one_hot_encoded_df = pd.get_dummies(source_df['source'], columns=all_sources, prefix='', prefix_sep='')\n",
    "\n",
    "    # Ensure all possible columns are included, filling missing with 0\n",
    "    one_hot_encoded_df = one_hot_encoded_df.reindex(columns=all_sources, fill_value=0)\n",
    "    one_hot_encoded_df['fullVisitorId'] = source_df['fullVisitorId']\n",
    "    source_df = one_hot_encoded_df.groupby('fullVisitorId').sum().reset_index()\n",
    "    # Merge the one-hot encoded columns back into the main DataFrame\n",
    "    #df = pd.merge(df, one_hot_encoded_df, on='fullVisitorId', how='inner')\n",
    "    # Aggregate the data\n",
    "    # columns_to_sum = one_hot_encoded_df.columns.to_list()\n",
    "    # columns_to_sum.remove('fullVisitorId')  # Ensure 'fullVisitorId' is not summed\n",
    "    # df = df.groupby('fullVisitorId').agg({col: 'sum' for col in columns_to_sum}).reset_index()\n",
    "        \n",
    "    # Fill missing values for 'pageviews' and 'bounces'\n",
    "    df['pageviews'].fillna(0, inplace=True)\n",
    "    df['bounces'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Replace missing 'transactionRevenue' with 0 and convert to int\n",
    "    df['transactionRevenue'].fillna(0, inplace=True)\n",
    "    df['transactionRevenue'] = df['transactionRevenue'].astype(int)\n",
    "    \n",
    "    # Create a binary 'Conversion' flag\n",
    "    df['Conversion'] = df['transactionRevenue'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    df['at_least_one_conversion'] = df.groupby('fullVisitorId')['Conversion'].transform('sum').apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    # Sort data by 'fullVisitorId' and 'date'\n",
    "    df.sort_values(by=['fullVisitorId', 'date'], inplace=True)\n",
    "    \n",
    "    # Identify and drop constant columns except 'bounces'\n",
    "    constant_columns = [col for col in df.columns if df[col].nunique() == 1 and col not in['Bounces','isTrueDirect']]    \n",
    "    df.drop(constant_columns, axis=1, inplace=True)\n",
    "    \n",
    "    # Drop other unnecessary columns\n",
    "    df.drop(['networkDomain', 'visitStartTime', 'visitNumber'], axis=1, inplace=True)\n",
    "    \n",
    "    # Merge data frames for channel visit analysis\n",
    "    first_visit_channel = df.groupby('fullVisitorId')['channelGrouping'].first().reset_index(name='FirstChannelVisit')\n",
    "    last_visit_channel = df.groupby('fullVisitorId')['channelGrouping'].last().reset_index(name='LastChannelVisit')\n",
    "    channels_first_last = pd.merge(first_visit_channel, last_visit_channel, on='fullVisitorId', how='inner')\n",
    "    \n",
    "    df_unique = df.drop_duplicates(subset='fullVisitorId', keep='first')\n",
    "    channels_first_last = pd.merge(channels_first_last, df_unique[['fullVisitorId', 'at_least_one_conversion', 'country', 'continent', 'subContinent']].drop_duplicates(), on='fullVisitorId', how='inner')\n",
    "    \n",
    "    \n",
    "    # Calculating the total number of visits by each user\n",
    "    total_visits_by_user=dict(df['fullVisitorId'].value_counts().reset_index(name='TotalVisits').values)\n",
    "\n",
    "    \n",
    "    # Calculating visits by channel for each user\n",
    "    channel_visits_by_user=dict(df.groupby('fullVisitorId')['channelGrouping'].value_counts())\n",
    "    list_of_dicts = []\n",
    "    for (visitor_id, channel), visits in channel_visits_by_user.items():\n",
    "        list_of_dicts.append({'fullVisitorId': visitor_id, channel: visits})\n",
    "\n",
    "    # Creating a DataFrame\n",
    "    df_channel_visits = pd.DataFrame(list_of_dicts)\n",
    "\n",
    "    # Combining all dictionaries representing the same fullVisitorId\n",
    "    df_channel_visits = df_channel_visits.groupby('fullVisitorId', as_index=False).sum()\n",
    "\n",
    "    \n",
    "    # Total pageviews by user\n",
    "    total_pageviews_by_user=dict(df.groupby('fullVisitorId')['pageviews'].sum().reset_index(name='TotalPageviews').values)\n",
    "\n",
    "    # Total bounces by user\n",
    "    total_bounces_by_user=dict(df.groupby('fullVisitorId')['bounces'].sum().reset_index(name='TotalBounces').values)\n",
    "\n",
    "\n",
    "    visits_by_device=dict(df.groupby('fullVisitorId')['deviceCategory'].value_counts())\n",
    "    # converting the dictionary to a list of dictionaries\n",
    "    list_of_dicts = []\n",
    "    for (visitor_id, device), visits in visits_by_device.items():\n",
    "        list_of_dicts.append({'fullVisitorId': visitor_id, device: visits})\n",
    "\n",
    "    # Creating a DataFrame\n",
    "    df_visits_by_device = pd.DataFrame(list_of_dicts)\n",
    "\n",
    "    # Combining all dictionaries representing the same fullVisitorId\n",
    "    df_visits_by_device = df_visits_by_device.groupby('fullVisitorId', as_index=False).sum()\n",
    "    \n",
    "    # Session pageviews\n",
    "    first_session_pageviews=dict(df.groupby('fullVisitorId')['pageviews'].first().reset_index(name='FirstSessionPageviews').values)\n",
    "    last_session_pageviews=dict(df.groupby('fullVisitorId')['pageviews'].last().reset_index(name='LastSessionPageviews').values)\n",
    "    \n",
    "    # Campaign data adjustment\n",
    "    df['campaign'] = df['campaign'].apply(lambda x: 0 if x == '(not set)' else 1)\n",
    "    \n",
    "    # Calculating campaign visits\n",
    "    campaign_visits_by_user=dict(df.groupby('fullVisitorId')['campaign'].sum().reset_index(name='CampaignVisits').values)\n",
    "\n",
    "    \n",
    "    # TrueDirect and AdContent data handling\n",
    "    df['isTrueDirect'] = df['isTrueDirect'].fillna(False)\n",
    "    true_Direct_by_user=dict(df.groupby('fullVisitorId')['isTrueDirect'].sum().reset_index(name='isTrueDirect').values)\n",
    "\n",
    "    adcontent_by_user=dict(df.groupby('fullVisitorId')['adContent'].apply(lambda x: x.notnull().sum()).reset_index(name='AdContentVisits').values)\n",
    "\n",
    "\n",
    "    # Convert dictionaries to DataFrames\n",
    "    df_total_bounces = pd.DataFrame(list(total_bounces_by_user.items()), columns=['fullVisitorId', 'TotalBounces'])\n",
    "    df_total_visits = pd.DataFrame(list(total_visits_by_user.items()), columns=['fullVisitorId', 'TotalVisits'])\n",
    "    df_total_pageviews = pd.DataFrame(list(total_pageviews_by_user.items()), columns=['fullVisitorId', 'TotalPageviews'])\n",
    "    df_first_session_pageviews = pd.DataFrame(list(first_session_pageviews.items()), columns=['fullVisitorId', 'FirstSessionPageviews'])\n",
    "    df_last_session_pageviews = pd.DataFrame(list(last_session_pageviews.items()), columns=['fullVisitorId', 'LastSessionPageviews'])\n",
    "    df_campaign_visits = pd.DataFrame(list(campaign_visits_by_user.items()), columns=['fullVisitorId', 'CampaignVisits'])\n",
    "    df_true_Direct = pd.DataFrame(list(true_Direct_by_user.items()), columns=['fullVisitorId', 'isTrueDirect'])\n",
    "    df_adcontent_visits = pd.DataFrame(list(adcontent_by_user.items()), columns=['fullVisitorId', 'AdContentVisits'])\n",
    "\n",
    "    # Merging all computed DataFrames\n",
    "    data_frames_to_merge = [\n",
    "        df_total_visits, df_total_bounces, df_channel_visits,\n",
    "        df_total_pageviews, df_visits_by_device, df_first_session_pageviews,\n",
    "        df_last_session_pageviews, df_campaign_visits, df_true_Direct,source_df,\n",
    "        df_adcontent_visits\n",
    "    ]\n",
    "\n",
    "    final_df = channels_first_last\n",
    "    for data_frame in data_frames_to_merge:\n",
    "        final_df = pd.merge(final_df, data_frame, on='fullVisitorId', how='inner')\n",
    "    \n",
    "    # Convert any floating-point columns to integers if necessary\n",
    "    for col in final_df.select_dtypes(include=['float64']).columns:\n",
    "        final_df[col] = final_df[col].astype(int)\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ensure you have correctly split your dataset first\n",
    "# preprocessed_train = preprocess_data(train_df.copy(), unique_sources=unique_sources)\n",
    "# preprocessed_test = preprocess_data(test_df.copy(), unique_sources=unique_sources)\n",
    "\n",
    "# Apply preprocessing to both train and test datasets\n",
    "processed_train = preprocess_data(train_df, all_sources)\n",
    "processed_test = preprocess_data(test_df, all_sources)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514185, 406)\n",
      "(214828, 406)\n"
     ]
    }
   ],
   "source": [
    "print(processed_train.shape)\n",
    "print(processed_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fullVisitorId', 'FirstChannelVisit', 'LastChannelVisit',\n",
       "       'at_least_one_conversion', 'country', 'continent', 'subContinent',\n",
       "       'TotalVisits', 'TotalBounces', 'Organic Search',\n",
       "       ...\n",
       "       'us.wow.com', 'voice.google.com', 'espanol.search.yahoo.com',\n",
       "       'meetup.com', '0.shared.bow.cat2.ads-bow.tl.borg.google.com:9847',\n",
       "       'it.pinterest.com', 'mmisciagna2.sbo.corp.google.com:8000',\n",
       "       'google.com.pe', '0.shared.bow.cat2.ads-bow.yw.borg.google.com:9898',\n",
       "       'AdContentVisits'],\n",
       "      dtype='object', length=406)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_test.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
